version: '3.8'

services:
  # Redis for job queues and caching
  redis:
    image: redis:7-alpine
    container_name: learning-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - streaming

  # FFmpeg transcoding service
  ffmpeg-worker:
    build:
      context: .
      dockerfile: Dockerfile.ffmpeg
    container_name: learning-ffmpeg
    environment:
      - REDIS_URL=redis://redis:6379
      - GOOGLE_CLOUD_PROJECT_ID=${GOOGLE_CLOUD_PROJECT_ID}
      - GOOGLE_CLOUD_BUCKET_NAME=${GOOGLE_CLOUD_BUCKET_NAME}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/gcloud-key.json
      - TEMP_DIR=/tmp/video-processing
      - MAX_CONCURRENT_JOBS=2
    volumes:
      - ./config/gcloud-key.json:/app/config/gcloud-key.json:ro
      - ffmpeg_temp:/tmp/video-processing
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - streaming

  # Video processor worker
  video-processor:
    build:
      context: .
      dockerfile: Dockerfile.processor
    container_name: learning-video-processor
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://redis:6379
      - GOOGLE_CLOUD_PROJECT_ID=${GOOGLE_CLOUD_PROJECT_ID}
      - GOOGLE_CLOUD_BUCKET_NAME=${GOOGLE_CLOUD_BUCKET_NAME}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/gcloud-key.json
      - CDN_BASE_URL=${CDN_BASE_URL}
      - JWT_SECRET=${JWT_SECRET}
      - TEMP_DIR=/tmp/processing
    volumes:
      - ./config/gcloud-key.json:/app/config/gcloud-key.json:ro
      - processor_temp:/tmp/processing
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "node", "/app/healthcheck.js"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - streaming

  # NGINX for streaming proxy and load balancing
  nginx-streaming:
    build:
      context: ./nginx
      dockerfile: Dockerfile.streaming
    container_name: learning-nginx-streaming
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./nginx/streaming.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    depends_on:
      - video-processor
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - streaming
      - web

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: learning-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - monitoring
      - streaming

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: learning-grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - monitoring
      - web

  # Node exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: learning-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  # Redis exporter for Redis metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: learning-redis-exporter
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    depends_on:
      - redis
    networks:
      - monitoring
      - streaming

  # Log aggregation with Loki
  loki:
    image: grafana/loki:latest
    container_name: learning-loki
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring

  # Log collection with Promtail
  promtail:
    image: grafana/promtail:latest
    container_name: learning-promtail
    volumes:
      - ./monitoring/promtail.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - monitoring

  # Message queue for job coordination
  rabbitmq:
    image: rabbitmq:3-management
    container_name: learning-rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_USER:-admin}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASS:-admin123}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - streaming

  # Video analytics service
  analytics-service:
    build:
      context: .
      dockerfile: Dockerfile.analytics
    container_name: learning-analytics
    environment:
      - NODE_ENV=production
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=${DATABASE_URL}
      - ANALYTICS_BATCH_SIZE=1000
      - ANALYTICS_FLUSH_INTERVAL=60000
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
    networks:
      - streaming

volumes:
  redis_data:
    driver: local
  ffmpeg_temp:
    driver: local
  processor_temp:
    driver: local
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  loki_data:
    driver: local
  rabbitmq_data:
    driver: local

networks:
  streaming:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  web:
    external: true
  monitoring:
    driver: bridge

# Health check configuration
x-healthcheck: &default-healthcheck
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

# Resource constraints template
x-resources: &default-resources
  deploy:
    resources:
      limits:
        memory: 1G
      reservations:
        memory: 512M

# Logging configuration
x-logging: &default-logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"